# Samsara Alert AI Service

Microservicio FastAPI que procesa alertas de Samsara usando **OpenAI GPT-4o** (vÃ­a LiteLLM) con Google ADK.

**Integrado con Laravel** mediante Redis Queue para procesamiento asÃ­ncrono en background.

## ğŸ“ Estructura del Proyecto

```
ai-service/
â”œâ”€â”€ main.py                      # Punto de entrada de FastAPI
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ .env.example                 # Template de variables de entorno
â”‚
â”œâ”€â”€ config/                      # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py              # Settings: Samsara, OpenAI, Service, Breadcrumbs
â”‚
â”œâ”€â”€ agents/                      # Agentes ADK
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompts.py               # System instructions de cada agente
â”‚   â””â”€â”€ agent_definitions.py     # DefiniciÃ³n de los 4 agentes (ingestion, panic, final, root)
â”‚
â”œâ”€â”€ tools/                       # Tools para agentes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ samsara_tools.py         # Tools de Samsara API (stats, events, camera)
â”‚
â”œâ”€â”€ core/                        # LÃ³gica central del servicio
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ runtime.py               # Runner y SessionService de ADK
â”‚
â””â”€â”€ api/                         # API FastAPI
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ routes.py                # Endpoints (stream, health)
    â”œâ”€â”€ models.py                # Pydantic models (request/response)
    â””â”€â”€ breadcrumbs.py           # LÃ³gica de creaciÃ³n de breadcrumbs
```

## ğŸ¯ SeparaciÃ³n de Responsabilidades

### ğŸ“‚ `config/`
- **PropÃ³sito**: ConfiguraciÃ³n centralizada
- **Archivos**:
  - `settings.py`: Todas las variables de entorno y constantes
- **Responsabilidad**: Gestionar configuraciÃ³n del servicio

### ğŸ“‚ `agents/`
- **PropÃ³sito**: DefiniciÃ³n de agentes ADK
- **Archivos**:
  - `prompts.py`: System instructions separadas por agente
  - `agent_definitions.py`: ConfiguraciÃ³n de LlmAgent y SequentialAgent
- **Responsabilidad**: LÃ³gica de negocio de los agentes

### ğŸ“‚ `tools/`
- **PropÃ³sito**: Herramientas para los agentes
- **Archivos**:
  - `samsara_tools.py`: Funciones async para interactuar con Samsara API
- **Responsabilidad**: IntegraciÃ³n con APIs externas

### ğŸ“‚ `core/`
- **PropÃ³sito**: Infraestructura central de ADK
- **Archivos**:
  - `runtime.py`: InicializaciÃ³n de Runner y SessionService
- **Responsabilidad**: Runtime de ejecuciÃ³n de agentes

### ğŸ“‚ `api/`
- **PropÃ³sito**: Capa de API HTTP
- **Archivos**:
  - `routes.py`: DefiniciÃ³n de endpoints FastAPI
  - `models.py`: Schemas Pydantic para request/response
  - `breadcrumbs.py`: ConversiÃ³n de eventos ADK a breadcrumbs SSE
- **Responsabilidad**: Interfaz HTTP y streaming

### ğŸ“„ `main.py`
- **PropÃ³sito**: Punto de entrada
- **Responsabilidad**: Inicializar FastAPI y registrar rutas

### Flujo de datos

```
Samsara Webhook â†’ Laravel â†’ Crea SamsaraEvent â†’ Redis Queue
                                                      â†“
                                                 Worker procesa
                                                      â†“
                                            FastAPI POST /alerts/ingest
                                                      â†“
                                            Sequential Agent Pipeline:
                                              1. ingestion_agent
                                              2. panic_investigator (con tools)
                                              3. final_agent
                                                      â†“
                                            Retorna assessment + message
                                                      â†“
                                            Laravel guarda resultados en DB

Frontend â†’ Laravel API â†’ GET /api/events/{id}/stream (SSE)
```

## ğŸš€ InstalaciÃ³n

### Con Poetry (recomendado)

```bash
# Instalar dependencias con Poetry
poetry install

# Activar el entorno virtual
poetry shell

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu OPENAI_API_KEY
```

### Con pip (alternativo)

```bash
# Generar requirements.txt desde Poetry
poetry export -f requirements.txt --output requirements.txt --without-hashes

# Instalar con pip
pip install -r requirements.txt
```

> ğŸ“– **Nota**: Ver [OPENAI_SETUP.md](OPENAI_SETUP.md) para guÃ­a completa de configuraciÃ³n de OpenAI y LiteLLM.

## ğŸƒ EjecuciÃ³n

```bash
# Con Poetry (recomendado)
poetry run python main.py

# O con uvicorn directamente
poetry run uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Si ya estÃ¡s en el shell de Poetry (poetry shell)
python main.py
# o
uvicorn main:app --reload
```

## ğŸ“¡ Endpoints

### POST /alerts/ingest

Procesa una alerta de Samsara de forma sÃ­ncrona (llamado por Laravel Job).

**Request:**
```json
{
  "event_id": 123,
  "payload": {
    "alertType": "panic",
    "vehicle": {"id": "123", "name": "CamiÃ³n 1234-ABC"},
    "driver": {"id": "456", "name": "Juan PÃ©rez"},
    "severity": "critical"
  }
}
```

**Response:**
```json
{
  "status": "success",
  "event_id": 123,
  "assessment": {...},
  "message": "ğŸš¨ ALERTA CRÃTICA..."
}
```

### GET /health

Health check del servicio.

## ğŸ§ª Pruebas

```bash
# Enviar alerta de prueba
curl -X POST http://localhost:8000/alerts/ai/stream \
  -H "Content-Type: application/json" \
  -d '{
    "payload": {
      "alertType": "panic",
      "vehicle": {"id": "123", "name": "CamiÃ³n 1234-ABC"},
      "driver": {"id": "456", "name": "Juan PÃ©rez"},
      "time": "2024-01-15T14:32:00Z",
      "severity": "critical"
    }
  }'
```

## ğŸ”§ Ventajas de esta Estructura

âœ… **Modularidad**: Cada mÃ³dulo tiene una responsabilidad clara  
âœ… **Mantenibilidad**: FÃ¡cil encontrar y modificar cÃ³digo especÃ­fico  
âœ… **Testabilidad**: Cada mÃ³dulo puede testearse independientemente  
âœ… **Escalabilidad**: FÃ¡cil agregar nuevos agentes, tools o endpoints
### 1. **ConfiguraciÃ³n Centralizada** (`config/`)
- Todas las variables de entorno en un solo lugar
- Clases organizadas: `SamsaraConfig`, `OpenAIConfig`, `ServiceConfig`, `BreadcrumbConfig`
- Usa OpenAI GPT-4o y GPT-4o-mini vÃ­a LiteLLM
- FÃ¡cil de mantener y modificar

## ğŸ“ DÃ³nde Modificar Cada Cosa

| Necesito...                          | Archivo a modificar                |
|--------------------------------------|------------------------------------|
| Cambiar un prompt de agente          | `agents/prompts.py`                |
| Agregar un nuevo agente              | `agents/agent_definitions.py`      |
| Agregar una nueva tool               | `tools/samsara_tools.py`           |
| Cambiar configuraciÃ³n de API         | `config/settings.py`               |
| Agregar un nuevo endpoint            | `api/routes.py`                    |
| Modificar formato de breadcrumbs     | `api/breadcrumbs.py`               |
| Cambiar modelos de request/response  | `api/models.py`                    |
| Ajustar el Runner                    | `core/runtime.py`                  |
